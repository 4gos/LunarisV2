{% extends "base.html" %}
{% block content %}

<div class="inicio-content">
    <section id="presentacion">
        <h2>Presentación del proyecto</h2>
    
        <p>
            Lunaris es una herramienta experimental basada en inteligencia artificial
            para la clasificación de lesiones cutáneas.
        </p>
    
        <p>Intenta:</p>
    
        <ul class="objetivos">
            <li>
                Facilitar el uso a través del diseño de una interfaz gráfica interactiva
                y accesible basada en el modelo de Deep Learning elegido, permitiendo su
                utilización por profesionales sin formación en bioinformática.
            </li>
            <li>
                Implementar recursos de explicabilidad en modelos de deep learning
                mediante técnicas de XAI que permitan interpretar las decisiones del
                sistema y fortalecer la confianza clínica.
            </li>
            <li>
                Promover la construcción de un repositorio local de imágenes
                dermatoscópicas que contribuya a la disponibilidad de datos públicos.
            </li>
            <li>
            
            La última versión del modelo Vision Transformer (ViT) implementada en este sistema de apoyo al diagnóstico representa un cambio conceptual relevante respecto de los enfoques clásicos basados en Redes Neuronales Convolucionales (CNN). Su funcionamiento se apoya en mecanismos originalmente desarrollados para el procesamiento del lenguaje natural, adaptados al análisis de imágenes médicas, en este caso, imágenes dermatoscópicas de lesiones cutáneas.
            
            A diferencia de las CNN, que procesan la imagen mediante filtros locales que recorren la imagen de forma jerárquica, el modelo ViT aborda la imagen como una secuencia de fragmentos o *patches*, de manera análoga a cómo un modelo de lenguaje procesa palabras dentro de una oración. En la etapa inicial, cada imagen dermatoscópica de entrada es redimensionada a un tamaño fijo y luego dividida en pequeños parches cuadrados de igual dimensión. Cada uno de estos parches contiene información visual local —color, textura y patrones morfológicos— relevante para la caracterización de la lesión.
            
            Estos parches no se procesan directamente como imágenes, sino que primero se transforman en vectores numéricos mediante una proyección lineal. A cada vector se le añade información posicional, lo que permite al modelo conservar la noción espacial de dónde se encuentra cada parche dentro de la imagen original. Este paso es fundamental, ya que, a diferencia de las CNN, los transformadores no incorporan de forma implícita la estructura espacial de la imagen y requieren que esta información sea codificada explícitamente.
            
            Una vez obtenida la secuencia de embeddings, el núcleo del modelo ViT entra en funcionamiento a través de múltiples capas de *self-attention* (autoatención). Este mecanismo permite que cada parche “observe” a todos los demás parches de la imagen y determine cuáles son más relevantes para la tarea de clasificación. En el contexto de lesiones dermatológicas, esto significa que el modelo puede relacionar simultáneamente regiones distantes de la imagen, por ejemplo, comparar variaciones de color en diferentes sectores de una lesión o analizar la coherencia global de los bordes y la simetría. Esta capacidad de capturar relaciones globales constituye una de las principales ventajas del ViT frente a enfoques puramente convolucionales.
            
            La última versión del modelo implementado en este trabajo utiliza una arquitectura ViT preentrenada mediante *transfer learning*. Esto implica que el modelo fue inicialmente entrenado sobre grandes bases de datos genéricas de imágenes, lo que le permitió aprender representaciones visuales generales, y posteriormente fue ajustado con imágenes dermatoscópicas específicas. Este enfoque resulta especialmente ventajoso en el ámbito médico, donde la disponibilidad de datos etiquetados suele ser limitada, y contribuye a mejorar la estabilidad y capacidad de generalización del sistema.
            
            Durante la fase de entrenamiento, el modelo ajusta sus parámetros internos para aprender patrones característicos de las distintas categorías de lesiones definidas en la clasificación adoptada: dermatosis cancerosa, dermatosis precancerosa, nevos, tumores benignos y otras lesiones. La salida final del ViT se obtiene a partir de un token especial de clasificación que sintetiza la información global de la imagen y es procesado por una capa densa que asigna probabilidades a cada clase. Estas probabilidades reflejan el grado de confianza del modelo en su predicción, información clave para su uso como herramienta de apoyo clínico.
            
            Un aspecto central de esta versión del sistema es la integración de técnicas de explicabilidad (*Explainable Artificial Intelligence*, XAI). A partir de los mapas de atención generados por el ViT, es posible visualizar qué regiones de la imagen influyeron con mayor peso en la decisión del modelo. Esto permite establecer un puente entre el razonamiento algorítmico y los criterios clínicos tradicionales, como la asimetría, los bordes irregulares o la variación cromática, fortaleciendo la interpretabilidad del resultado y la confianza del profesional de la salud.
            
            En conjunto, el funcionamiento del ViT en su última versión permite realizar un análisis global, contextual y explicable de las imágenes dermatoscópicas. Su capacidad para integrar información distribuida en toda la lesión, combinada con mecanismos de atención y explicabilidad, lo convierte en una herramienta especialmente adecuada para entornos clínicos reales, donde la precisión diagnóstica, la transparencia del sistema y el acompañamiento al criterio médico resultan fundamentales. De este modo, el modelo no reemplaza la evaluación clínica, sino que actúa como un apoyo inteligente que contribuye a una toma de decisiones más informada, objetiva y reproducible.

            </li>
        </ul>
    </section>
    
    <section id="quienes_somos">
        <h2>Quiénes somos</h2>
        <p>
            Somos Agostina y Lucia, estudiantes de ingeniería biomédica desarrollando un sistema
            amigable con el usuario para poder detectar de manera mas intuitiva las lesiones cutaneas.
            Siendo el usuario un profesional de la salud, Lunaris es una herramienta mas para ayudar a la deteccion de lesiones cutaneas.
        </p>
    </section>
</div>
{% endblock %}





